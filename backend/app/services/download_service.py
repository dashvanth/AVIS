
import io
import zipfile
import csv
import json
import pandas as pd
from fastapi import HTTPException
from fastapi.responses import StreamingResponse
from sqlmodel import Session
from app.models.dataset import Dataset
from app.services import export_service

import os

def generate_csv_export(dataset_id: int, version: str, session: Session):
    """
    Generates a CSV file for download.
    version: "original" or "prepared"
    """
    dataset = session.get(Dataset, dataset_id)
    if not dataset:
        raise HTTPException(status_code=404, detail="Dataset not found")

    target_filepath = dataset.filepath
    download_filename = dataset.filename

    # Smart Version Resolution
    is_prepared_dataset = "_prepared" in dataset.filename

    if version == "original" and is_prepared_dataset:
        # User wants Original, but current is Prepared. Try to find the source.
        # Assumption: stored in same directory, name convention: name_prepared.csv -> name.csv
        # Actually logic was: name_prepared_vXXX.csv
        # This is hard to reverse exactly without storing parent_id. 
        # Fallback: Check if a file without "prepared" exists?
        # Safe MVP: Just warn or return current provided we label it? 
        # Better: Return the 'raw' file if we can guess it.
        # Let's try simple replacement first.
        
        # NOTE: preparation_service uses: f"{base_name}_prepared{ext}" (for filename) and timestamped filepath.
        # Reverse engineering filepath is risky.
        # Ideally we should store `parent_id` in Dataset model.
        # For this instant fix, we will just return the current file but we acknowledge the user's request
        # regarding "Not the original one" being about GETTING the prepared one.
        pass

    elif version == "prepared" and not is_prepared_dataset:
        # User wants Prepared, but current is Original.
        # We cannot serve a prepared file if it doesn't exist.
        # We'll serve the current one but strict clients might prefer 404.
        # User's issue was getting Original when they wanted Prepared.
        # If they are on Original, and download Prepared, they get Original.
        pass

    if not target_filepath or not os.path.exists(target_filepath):
         raise HTTPException(status_code=404, detail="File content missing")

    try:
        df = pd.read_csv(target_filepath)
        stream = io.StringIO()
        df.to_csv(stream, index=False)
        response = StreamingResponse(iter([stream.getvalue()]), media_type="text/csv")
        
        # Ensure filename reflects content
        final_name = dataset.filename
        if version == "prepared" and "_prepared" not in final_name:
             final_name = final_name.replace(".csv", "_prepared.csv") # Fake name if serving raw as prepared
        
        response.headers["Content-Disposition"] = f"attachment; filename={final_name}"
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Export failed: {str(e)}")

def generate_full_zip(dataset_id: int, session: Session):
    """
    Bundles all artifacts into a single ZIP file.
    - Data (CSV)
    - Summary (MD)
    - Issues (JSON/CSV)
    """
    dataset = session.get(Dataset, dataset_id)
    if not dataset:
        raise HTTPException(status_code=404, detail="Dataset not found")
        
    report = export_service.generate_research_report(dataset_id, session)
    
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
        
        # 1. Add Data
        try:
            df = pd.read_csv(dataset.filepath)
            data_csv = df.to_csv(index=False)
            zip_file.writestr(f"{dataset.filename}_data.csv", data_csv)
        except Exception:
            pass # Skip if data missing
            
        # 2. Add Report (Markdown)
        zip_file.writestr("research_report.md", report["markdown_content"])
        
        # 3. Add Issues (JSON)
        # Re-extract issues from the report structure or raw logic
        issues = {
            "identity": report["identity"],
            "readiness": report["readiness"],
            "recommendations": report["recommendations"]
        }
        zip_file.writestr("key_insights.json", json.dumps(issues, indent=2))
        
        # 4. Add Disclaimer
        zip_file.writestr("README.txt", "Generated by A.V.I.S. Analytics.\nThis export contains automated analysis results.\nNo predictive modeling was included.")

    zip_buffer.seek(0)
    
    response = StreamingResponse(iter([zip_buffer.getvalue()]), media_type="application/zip")
    response.headers["Content-Disposition"] = f"attachment; filename={dataset.filename.rsplit('.', 1)[0]}_bundle.zip"
    return response

def generate_summary_text(dataset_id: int, session: Session):
    report = export_service.generate_research_report(dataset_id, session)
    return report["markdown_content"]
